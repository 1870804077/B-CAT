import time
import torch
import crypten
from multiprocess_launcher import MultiProcessLauncher

# ================== âš™ï¸ å…¨å±€é…ç½® (Global Config) ==================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
RUNS = 1  # æ€§èƒ½æµ‹è¯•è¿è¡Œæ¬¡æ•°

# å‚æ•°é…ç½® (K1, K2)
K_PARAMS = [(1, 12), (3, 12)]

# âœ… ä¿®æ”¹ï¼šåŠ å…¥ BERT å¸¸ç”¨çš„ä¸‰ç»´å½¢çŠ¶æµ‹è¯•
TEST_SIZES = [
    (1, 2000),             # 2D åŸºç¡€æµ‹è¯•
    (1, 128, 768),         # æ¨¡æ‹Ÿ BERT: Batch=1, Seq=128, Hidden=768
    (8, 128, 768)          # æ¨¡æ‹Ÿ BERT: Batch=8, Seq=128, Hidden=768 (é«˜è´Ÿè½½)
]

# ================== ğŸ› ï¸ è¾…åŠ©å·¥å…· (Helpers) =====================

def inspect_cryptensor(name, enc_tensor):
    """
    ğŸ” è°ƒè¯•æ¢é’ˆï¼šæ‰“å° CrypTen å¼ é‡çš„è¯¦ç»†å†…éƒ¨ç»“æ„
    """
    # åªè®© Rank 0 æ‰“å°ï¼Œé˜²æ­¢å¤šè¿›ç¨‹è¾“å‡ºæ··ä¹±
    if crypten.comm.get().get_rank() == 0:
        print(f"\nğŸ” [INSPECT] {name}")
        print(f"  1. Wrapper Type (å¤–å±‚ç±»å‹): {type(enc_tensor)}")
        print(f"  2. Logical Size (é€»è¾‘å½¢çŠ¶): {enc_tensor.size()}")
        
        # è®¿é—® .share (ArithmeticSharedTensor)
        if hasattr(enc_tensor, 'share'):
            share = enc_tensor.share
            print(f"  3. Share Type   (åˆ†ç‰‡ç±»å‹): {type(share)}")
            
            # è®¿é—® ._tensor (å®é™…å­˜å‚¨æ•°æ®çš„ PyTorch Tensor)
            if hasattr(share, '_tensor'):
                raw_tensor = share._tensor
                print(f"  4. Raw ._tensor (åº•å±‚æ•°æ®): {type(raw_tensor)}")
                print(f"  5. Raw Size     (ç‰©ç†å½¢çŠ¶): {raw_tensor.size()}")
                print(f"  6. Device       (è®¾å¤‡ä½ç½®): {raw_tensor.device}")
        print("-" * 40)

def run_perf_benchmark(input_generator_func, operation_func):
    """
    æ‰§è¡Œå…·ä½“çš„æ€§èƒ½æµ‹è¯•å¾ªç¯ (ä¿®æ­£ç‰ˆï¼šå¢åŠ  CUDA åŒæ­¥å’Œé¢„çƒ­)
    """
    times, bytes_stats, rounds_stats = {}, {}, {}

    for size in TEST_SIZES:
        # 1. ç”Ÿæˆè¾“å…¥
        x_enc = input_generator_func(size)
        
        # ğŸ” æ’å…¥æ£€æŸ¥ç‚¹ï¼šç¡®è®¤è¾“å…¥æ˜¯å¦ä¸º 3D
        inspect_cryptensor(f"Input for size {size}", x_enc)
        
        # é¢„çƒ­ run
        operation_func(x_enc)
        if DEVICE == "cuda":
            torch.cuda.synchronize() # ç¡®ä¿é¢„çƒ­çœŸæ­£å®Œæˆ

        # 2. é‡ç½®é€šä¿¡ç»Ÿè®¡
        crypten.reset_communication_stats()

        if DEVICE == "cuda":
            torch.cuda.synchronize()

        # 3. è®¡æ—¶å¼€å§‹
        start_time = time.time()
        
        for _ in range(RUNS):
            operation_func(x_enc)
        
        if DEVICE == "cuda":
            torch.cuda.synchronize()

        # 4. è®°å½•æ•°æ®
        # ä½¿ç”¨å…ƒç´ æ€»æ•°ä½œä¸º keyï¼Œæˆ–è€…ç›´æ¥ç”¨ tuple
        dim_key = str(size) 
        times[dim_key] = time.time() - start_time
        
        stats = crypten.get_communication_stats()
        bytes_stats[dim_key] = stats["bytes"]
        rounds_stats[dim_key] = stats["rounds"]
        
    return times, bytes_stats, rounds_stats

def print_report(op_name, config_str, max_err, avg_err, times, bytes_stats, rounds_stats):
    """
    æ‰“å°æŠ¥å‘Šï¼šå…ˆæ‰“å°é…ç½®ï¼Œå†æ‰“å°ç²¾åº¦å’Œæ€§èƒ½
    """
    if crypten.comm.get().get_rank() == 0:
        print(f"\n{'='*20} ğŸ§ª {op_name} Test {'='*20}", flush=True)
        print(f"âš™ï¸  Configuration: {config_str}", flush=True)
        print("-" * 50, flush=True)
        
        print(f"âœ… Precision Check:", flush=True)
        print(f"   Max Error: {max_err:.8f}", flush=True)
        print(f"   Avg Error: {avg_err:.8f}", flush=True)
        
        print(f"ğŸš€ Performance (Avg over {RUNS} runs):", flush=True)
        for size in TEST_SIZES:
            dim_key = str(size)
            if dim_key in times:
                t = times[dim_key] / RUNS
                comm = bytes_stats[dim_key] / 1048576 / RUNS
                rnd = rounds_stats[dim_key] / RUNS
                # [FIX] è¿™é‡ŒåŠ ä¸Š str(size)ï¼Œå¦åˆ™å…ƒç»„æ— æ³•ä½¿ç”¨ :<15 æ ¼å¼åŒ–
                print(f"   Shape {str(size):<15}: Time: {t:.7f}s | Comm: {comm:.7f}MB | Rounds: {rnd:.0f}", flush=True)
        print("="*60, flush=True)

# ================== ğŸ§ª å…·ä½“æµ‹è¯•å‡½æ•° (Test Functions) ==================

def test_sigmoid():
    crypten.cfg.functions.sigmoid_tanh_method = "newer_time"
    
    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(-8, 8, 0.001, device=DEVICE)
        y_original = torch.sigmoid(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).sigmoid(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.zeros(size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.sigmoid(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Sigmoid", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)


def test_tanh():
    crypten.cfg.functions.sigmoid_tanh_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(-7, 7, 0.001, device=DEVICE)
        y_original = torch.tanh(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).tanh(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.zeros(size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.tanh(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Tanh", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)


def test_gelu():
    crypten.cfg.functions.gelu_method = "newer_time"
    approximate = "none"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(-5, 5, 0.001, device=DEVICE)
        y_original = torch.nn.functional.gelu(x, approximate=approximate)
        y_actual = crypten.cryptensor(x, device=DEVICE).gelu(approximate=approximate, k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            data = (torch.rand(*size, device=DEVICE) * 10) - 5
            return crypten.cryptensor(data, device=DEVICE)

        def op_func(enc_x):
            enc_x.gelu(approximate=approximate, k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("GeLU", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)


def test_silu():
    crypten.cfg.functions.silu_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(-15, 15, 0.001, device=DEVICE)
        y_original = torch.nn.functional.silu(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).silu(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            data = (torch.rand(*size, device=DEVICE) * 16) - 8
            return crypten.cryptensor(data, device=DEVICE)

        def op_func(enc_x):
            enc_x.silu(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("SiLU", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)


def test_exp():
    crypten.cfg.functions.exp_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.linspace(-16.0, -2.0, 10000, device=DEVICE)
        y_original = torch.exp(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).exp(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.zeros(size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.exp(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Exp", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)

def test_erf():
    crypten.cfg.functions.erf_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.linspace(-5.0, 5.0, 10000, device=DEVICE)
        y_original = torch.erf(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).erf(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            data = (torch.rand(*size, device=DEVICE) * 8) - 4
            return crypten.cryptensor(data, device=DEVICE)

        def op_func(enc_x):
            enc_x.erf(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Erf", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)

def test_reciprocal():
    crypten.cfg.functions.reciprocal_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(0.1, 5.0, 0.001, device=DEVICE)
        y_original = 1.0 / x
        y_actual = crypten.cryptensor(x, device=DEVICE).reciprocal(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.ones(size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.reciprocal(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Reciprocal", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)


def test_inv_sqrt():
    crypten.cfg.functions.sqrt_method = "newer_time"

    for k1, k2 in K_PARAMS:
        # 1. ç²¾åº¦éªŒè¯
        x = torch.arange(0.1, 5.0, 0.001, device=DEVICE)
        y_original = 1.0 / torch.sqrt(x)
        y_actual = crypten.cryptensor(x, device=DEVICE).inv_sqrt(k1=k1, k2=k2).get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 2. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.ones(size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.inv_sqrt(k1=k1, k2=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("InvSqrt", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)

def test_softmax():
    # 1. é…ç½®
    crypten.cfg.functions.softmax_method = "newer"
    crypten.cfg.functions.reciprocal_method = "newer_time"
    crypten.cfg.functions.exp_method = "newer_time"
    
    for k1, k2 in K_PARAMS:
        # 2. ç²¾åº¦éªŒè¯
        x = torch.randn(1, 128, device=DEVICE) 
        y_original = torch.nn.functional.softmax(x, dim=-1)
        
        x_enc = crypten.cryptensor(x, device=DEVICE)
        y_mpc = x_enc.softmax(dim=-1, k1=k1, k2_exp=k2, k2_recip=k2)
        y_actual = y_mpc.get_plain_text()
        
        diff = (y_original.cpu() - y_actual.cpu()).abs()
        max_err, avg_err = diff.max(), diff.mean()

        # 3. æ€§èƒ½æµ‹è¯•
        def input_gen(size):
            return crypten.cryptensor(torch.randn(*size, device=DEVICE), device=DEVICE)

        def op_func(enc_x):
            enc_x.softmax(dim=-1, k1=k1, k2_exp=k2, k2_recip=k2)

        times, comms, rounds = run_perf_benchmark(input_gen, op_func)
        print_report("Softmax", f"k1={k1}, k2={k2}", max_err, avg_err, times, comms, rounds)

# ================== ğŸš€ ä¸»ç¨‹åº (Main) ==================

def main():
    crypten.init()
    print(f"ğŸš€ Running tests on device: {DEVICE}")
    
    # ä½ å¯ä»¥æ³¨é‡Šæ‰ä¸éœ€è¦è·‘çš„æµ‹è¯•
    test_sigmoid()
    test_tanh()
    test_exp()
    test_erf()
    test_reciprocal()
    test_inv_sqrt()
    test_gelu()
    test_silu()
    test_softmax()

if __name__ == "__main__":
    launcher = MultiProcessLauncher(2, main)
    launcher.start()
    launcher.join()
    launcher.terminate()