#!/bin/bash

# # =======================================================
# # 1. ç½‘ç»œä¸ŽçŽ¯å¢ƒé…ç½®
# # =======================================================
# export CUDA_VISIBLE_DEVICES=0
# export HF_ENDPOINT=https://hf-mirror.com
# export HF_HUB_DOWNLOAD_TIMEOUT=120

# SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
# SHAFT_LIB_PATH="$SCRIPT_DIR/.."
# export PYTHONPATH=$PYTHONPATH:.:$SHAFT_LIB_PATH

# TASK="sst2"
# BATCH_SIZE_TRAIN=32
# # å°†æŽ¨ç† Batch Size è®¾ä¸º 1 ä»¥é¿å… MPC æ˜¾å­˜æº¢å‡º (OOM)
# BATCH_SIZE_INFER=1 
# OUTPUT_ROOT="./checkpoints"

# # æœ¬åœ°æ¨¡åž‹ç›®å½•
# LOCAL_MODEL_DIR="./bert-base-uncased"
# # å¾®è°ƒåŽäº§å‡ºçš„æ¨¡åž‹ç›®å½•
# APPROX_MODEL_DIR="$OUTPUT_ROOT/test_var_${TASK}_approx"

# # echo "======================================================="
# # echo "ðŸš€ SHAFT Test: $TASK"
# # echo "   Device: ($CUDA_VISIBLE_DEVICES)"
# # echo "   Mirror: $HF_ENDPOINT"
# # echo "======================================================="

# # # =======================================================
# # # 2. æ™ºèƒ½è½»é‡åŒ–ä¸‹è½½ (å‡çº§ç‰ˆï¼šæ£€æŸ¥å…·ä½“æ–‡ä»¶)
# # # =======================================================
# # echo -e "\nðŸ› ï¸  Checking Base Model..."

# # # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè€Œä¸ä»…ä»…æ˜¯æ–‡ä»¶å¤¹
# # if [ ! -f "$LOCAL_MODEL_DIR/vocab.txt" ] || [ ! -f "$LOCAL_MODEL_DIR/pytorch_model.bin" ]; then
# #     echo "   âš ï¸  Model files missing or incomplete. Downloading PyTorch weights..."
    
# #     if ! command -v huggingface-cli &> /dev/null; then
# #         echo "   Installing huggingface-cli..."
# #         pip install -U "huggingface_hub[cli]"
# #     fi

# #     # åªä¸‹è½½å¿…è¦æ–‡ä»¶ (çº¦ 400MB)
# #     huggingface-cli download google-bert/bert-base-uncased \
# #         --local-dir "$LOCAL_MODEL_DIR" \
# #         --local-dir-use-symlinks False \
# #         --resume-download \
# #         --include "config.json" "pytorch_model.bin" "vocab.txt" "tokenizer.json" "tokenizer_config.json" "*.safetensors"

# #     if [ $? -ne 0 ]; then
# #         echo "âŒ Download failed. Please check network."
# #         exit 1
# #     fi
# #     echo "âœ… Download finished."
# # else
# #     echo "âœ… Base model verified at: $LOCAL_MODEL_DIR"
# # fi

# # =======================================================
# # Step 1: æ˜Žæ–‡å¾®è°ƒ
# # =======================================================
# echo -e "\n[Step 1/3] Starting Plaintext Fine-tuning..."

# python model_modify.py \
#     --model_name_or_path "$LOCAL_MODEL_DIR" \
#     --task $TASK \
#     --output_dir $OUTPUT_ROOT \
#     --batch_size $BATCH_SIZE_TRAIN \
#     --num_train_epochs 3 \
#     --learning_rate 2e-5 \
#     --approx_num_train_epochs 1 \
#     --approx_learning_rate 1e-5 

# if [ $? -ne 0 ]; then
#     echo "âŒ Training failed! Exiting."
#     exit 1
# fi

# # # =======================================================
# # # Step 2: æ˜Žæ–‡è¯„ä¼°
# # # =======================================================
# # echo -e "\n[Step 2/3] Running Plaintext Evaluation..."

# # python run_glue_eval.py \
# #     --model_name_or_path "$APPROX_MODEL_DIR" \
# #     --task_name $TASK \
# #     --per_device_eval_batch_size 32 \
# #     --output_dir "${APPROX_MODEL_DIR}/eval_plain"

# # =======================================================
# # Step 3: å¯†æ–‡æŽ¨ç†
# # =======================================================
# # echo -e "\n[Step 3/3] Running SHAFT Encrypted Inference..."

# # python run_glue_private.py \
# #     --model_name_or_path "$APPROX_MODEL_DIR" \
# #     --task_name $TASK \
# #     --acc \
# #     --max_length 128 \
# #     --per_device_eval_batch_size $BATCH_SIZE_INFER \
# #     --output_dir "${APPROX_MODEL_DIR}/eval_private" \
# #     --ignore_mismatched_sizes

# echo "======================================================="
# echo "âœ… All Done! Results saved in $APPROX_MODEL_DIR"
# echo "======================================================="



#!/bin/bash
export HF_ENDPOINT=https://hf-mirror.com
# å®šä¹‰ç»“æžœè¾“å‡ºæ–‡ä»¶
RESULT_FILE="./results.txt"

# åˆå§‹åŒ–ç»“æžœæ–‡ä»¶
echo "==========================================================" > "$RESULT_FILE"
echo "ðŸš€ Batch Benchmark Started at $(date)" | tee -a "$RESULT_FILE"
echo "==========================================================" | tee -a "$RESULT_FILE"

run_task() {
    TASK_NAME=$1
    EPOCHS=$2

    echo "" | tee -a "$RESULT_FILE"
    echo "##########################################################" | tee -a "$RESULT_FILE"
    echo "â–¶ï¸  STARTING TASK: $TASK_NAME (Epochs: $EPOCHS)" | tee -a "$RESULT_FILE"
    echo "##########################################################" | tee -a "$RESULT_FILE"

    # ã€ä¿®æ”¹ã€‘åŠ å…¥äº† --disable_tqdm å‚æ•°
    python model_modify.py \
        --task "$TASK_NAME" \
        --num_train_epochs "$EPOCHS" \
        --approx_num_train_epochs "$EPOCHS" \
        # --disable_tqdm \
        2>&1 | tee -a "$RESULT_FILE"
    
    echo "" | tee -a "$RESULT_FILE"
    echo "âœ… Finished $TASK_NAME" | tee -a "$RESULT_FILE"
}

# ==========================================
# ä»»åŠ¡åˆ—è¡¨
# ==========================================
run_task "sst2" 1
run_task "qnli" 1
run_task "cola" 3

echo "" | tee -a "$RESULT_FILE"
echo "==========================================================" | tee -a "$RESULT_FILE"
echo "ðŸŽ‰ All tasks completed successfully!" | tee -a "$RESULT_FILE"
echo "==========================================================" | tee -a "$RESULT_FILE"